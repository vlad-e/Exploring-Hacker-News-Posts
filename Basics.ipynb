{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News posts\n",
    "\n",
    "**Objectives:**\n",
    "\n",
    "This early DataQuest project is a chance to try to explore the data and extract information without the Pandas library\n",
    "\n",
    "**Resources used:**\n",
    "\n",
    "Anaconda distribution - Jupyter Notebook v 5.7.8, Python 3.7.3\n",
    "\n",
    "\n",
    "First, we will open the file using Python's *open* command, read it and split it by the new line delimiter and comma,thus getting ourselves a list of lists in Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "f_o = open(\"hacker_news.csv\")\n",
    "f_r = f_o.read()\n",
    "f_s = f_r.split(\"\\n\")\n",
    "hn = []\n",
    "for row in f_s:\n",
    "    hn.append(row.split(\",\"))\n",
    "print(hn[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n"
     ]
    }
   ],
   "source": [
    "#Further splitting the list - first the column headers\n",
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n"
     ]
    }
   ],
   "source": [
    "#then printing the first data row to check our results\n",
    "print(hn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "1581\n",
      "967\n",
      "17552\n"
     ]
    }
   ],
   "source": [
    "#Now, we'll split the posts by topic. The reason for \"try/except\" clause is an empty row that we need to skip over\n",
    "\n",
    "ask_posts = []\n",
    "show_posts = []\n",
    "other_posts = []\n",
    "\n",
    "for row in hn:\n",
    "        try:\n",
    "            title=row[1]\n",
    "            if title.lower().startswith(\"ask hn\"):\n",
    "                ask_posts.append(row)\n",
    "            elif title.lower().startswith(\"show hn\"):\n",
    "                show_posts.append(row)\n",
    "            else:\n",
    "                other_posts.append(row)\n",
    "        except:\n",
    "            print(row)\n",
    "            next\n",
    "print(len(ask_posts))\n",
    "print(len(show_posts))\n",
    "print(len(other_posts))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average no of ask comments: 14.371283997469956\n",
      "Average no of show comments: 10.415718717683557\n"
     ]
    }
   ],
   "source": [
    "#Further counting the number of comments in the dataset\n",
    "\n",
    "total_ask_comments = 0\n",
    "for item in ask_posts:\n",
    "    total_ask_comments = total_ask_comments + int(item[4])\n",
    "avg_ask_comments= total_ask_comments / len(ask_posts)\n",
    "print(\"Average no of ask comments: \" +str(avg_ask_comments))\n",
    "total_show_comments = 0\n",
    "for item in show_posts:\n",
    "    total_show_comments =total_show_comments + int(item[4])\n",
    "    \n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "\n",
    "print(\"Average no of show comments: \" +str(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step would be to build dictionaries and calculate averages based on comments per post per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 5.833333333333333], ['13', 15.688311688311689], ['10', 13.89090909090909], ['14', 14.03125], ['16', 17.816326530612244], ['12', 10.079365079365079], ['17', 11.965909090909092], ['15', 39.83018867924528], ['21', 14.206185567010309], ['20', 22.89189189189189], ['02', 24.78181818181818], ['03', 7.98], ['05', 7.85], ['18', 13.948453608247423], ['01', 9.686274509803921], ['19', 11.161904761904761], ['22', 6.292307692307692], ['23', 8.428571428571429], ['08', 9.840909090909092], ['04', 7.394736842105263], ['00', 8.25925925925926], ['07', 7.852941176470588], ['06', 9.555555555555555], ['11', 11.754716981132075]]\n"
     ]
    }
   ],
   "source": [
    "import datetime as dt\n",
    "result_list = []\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "for row in ask_posts:\n",
    "    result_list.append([row[6],int(row[4])])\n",
    "for row in result_list:\n",
    "    strp = dt.datetime.strptime(row[0],\"%m/%d/%Y %H:%M\")\n",
    "    hour = strp.strftime(\"%H\")\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] =1\n",
    "        comments_by_hour[hour]=row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] +=1\n",
    "        comments_by_hour[hour] = comments_by_hour[hour] + row[1]\n",
    "\n",
    "avg_by_hour = []\n",
    "for hour in counts_by_hour:\n",
    "    avg_by_hour.append([hour,comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[[8.25925925925926, '00'], [9.686274509803921, '01'], [24.78181818181818, '02'], [7.98, '03'], [7.394736842105263, '04'], [7.85, '05'], [9.555555555555555, '06'], [7.852941176470588, '07'], [9.840909090909092, '08'], [5.833333333333333, '09'], [13.89090909090909, '10'], [11.754716981132075, '11'], [10.079365079365079, '12'], [15.688311688311689, '13'], [14.03125, '14'], [39.83018867924528, '15'], [17.816326530612244, '16'], [11.965909090909092, '17'], [13.948453608247423, '18'], [11.161904761904761, '19'], [22.89189189189189, '20'], [14.206185567010309, '21'], [6.292307692307692, '22'], [8.428571428571429, '23']]\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1],row[0]])\n",
    "print(type(swap_avg_by_hour))\n",
    "sorted_swap = []\n",
    "sorted_swap = sorted(swap_avg_by_hour,key= lambda x: x[1])\n",
    "print(sorted_swap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments:\n",
      "<class 'list'>\n",
      "00:00: 8.26 average comments per post.\n",
      "[8.25925925925926, '00']\n",
      "01:00: 9.69 average comments per post.\n",
      "[9.686274509803921, '01']\n",
      "02:00: 24.78 average comments per post.\n",
      "[24.78181818181818, '02']\n",
      "03:00: 7.98 average comments per post.\n",
      "[7.98, '03']\n",
      "04:00: 7.39 average comments per post.\n",
      "[7.394736842105263, '04']\n",
      "05:00: 7.85 average comments per post.\n",
      "[7.85, '05']\n",
      "06:00: 9.56 average comments per post.\n",
      "[9.555555555555555, '06']\n",
      "07:00: 7.85 average comments per post.\n",
      "[7.852941176470588, '07']\n",
      "08:00: 9.84 average comments per post.\n",
      "[9.840909090909092, '08']\n",
      "09:00: 5.83 average comments per post.\n",
      "[5.833333333333333, '09']\n",
      "10:00: 13.89 average comments per post.\n",
      "[13.89090909090909, '10']\n",
      "11:00: 11.75 average comments per post.\n",
      "[11.754716981132075, '11']\n",
      "12:00: 10.08 average comments per post.\n",
      "[10.079365079365079, '12']\n",
      "13:00: 15.69 average comments per post.\n",
      "[15.688311688311689, '13']\n",
      "14:00: 14.03 average comments per post.\n",
      "[14.03125, '14']\n",
      "15:00: 39.83 average comments per post.\n",
      "[39.83018867924528, '15']\n",
      "16:00: 17.82 average comments per post.\n",
      "[17.816326530612244, '16']\n",
      "17:00: 11.97 average comments per post.\n",
      "[11.965909090909092, '17']\n",
      "18:00: 13.95 average comments per post.\n",
      "[13.948453608247423, '18']\n",
      "19:00: 11.16 average comments per post.\n",
      "[11.161904761904761, '19']\n",
      "20:00: 22.89 average comments per post.\n",
      "[22.89189189189189, '20']\n",
      "21:00: 14.21 average comments per post.\n",
      "[14.206185567010309, '21']\n",
      "22:00: 6.29 average comments per post.\n",
      "[6.292307692307692, '22']\n",
      "23:00: 8.43 average comments per post.\n",
      "[8.428571428571429, '23']\n"
     ]
    }
   ],
   "source": [
    "print(\"Top 5 Hours for Ask Posts Comments:\")\n",
    "print(type(sorted_swap))\n",
    "for row in sorted_swap:\n",
    "    print(row[1]+\":00: {:.2f} average comments per post.\".format(row[0]))\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.83018867924528, '15']\n"
     ]
    }
   ],
   "source": [
    "print(max(sorted_swap,key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the most active time of comment posting on the website is 1500 hours , which has an average of 39.83 comments per post.\n",
    "\n",
    "#### Conclusions\n",
    "\n",
    "In this project we aimed to work with data without using the pandas library and keep to pure Python code. The results can seem rather confusing, since the most active time of post responses is in the middle of the day, when people are working."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
